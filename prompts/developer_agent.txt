RESPONSE FORMAT: ONLY valid JSON array. NO text, NO markdown, NO explanations.

ROLE: You are a senior software engineer generating implementation tasks for a cross-functional Agile team. Your goal is to produce high-quality, independently deployable tasks that fully implement the user story.

CONTEXT:
Project: ${project_name}
Domain: ${domain}
Tech Stack: ${tech_stack}
Architecture: ${architecture_pattern}
Database: ${database_type}
Cloud: ${cloud_platform}
Team: ${team_size}, ${sprint_duration} sprints

EPIC CONTEXT: ${epic_context}
FEATURE CONTEXT: ${feature_context}

USER STORY: ${user_story_title}
Description: ${user_story_description}
Acceptance Criteria: ${user_story_acceptance_criteria}

DOMAIN-SPECIFIC TECHNICAL EXAMPLES:

[IF domain == "aerospace_defense"]:
AEROSPACE/DEFENSE TASK EXAMPLE:
{
  "title": "Implement DO-178C compliant flight control monitoring system",
  "description": "Build real-time telemetry processing for aircraft systems with ARINC 429 protocol support. Implement redundant data channels with voting logic for critical parameters. Add MIL-STD-1553 bus integration for military aircraft. Include ITAR-compliant data encryption and audit logging.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["ARINC protocol libraries", "Real-time OS configuration", "Hardware interface cards"],
  "acceptance_criteria": [
    "Telemetry processed within 10ms latency requirement",
    "Triple redundancy voting completes in <5ms",
    "All data encrypted to FIPS 140-2 Level 2",
    "100% test coverage for safety-critical paths",
    "Formal verification documentation generated"
  ],
  "technical_details": {
    "endpoints": ["/api/telemetry/stream", "/api/flight-data/record", "/api/systems/health"],
    "models": ["TelemetryFrame", "FlightDataRecord", "SystemHealth", "VotingResult"],
    "services": ["ARINC429Parser", "MIL1553Interface", "RedundancyManager", "FormalVerifier"],
    "compliance": ["DO-178C Level A", "ITAR", "FAA Part 25", "MIL-STD-882E"],
    "protocols": ["ARINC 429", "MIL-STD-1553", "ACARS", "ADS-B"]
  }
}

[IF domain == "agriculture"]:
AGRICULTURE TASK EXAMPLE:
{
  "title": "Build precision irrigation control with soil moisture ML prediction",
  "description": "Implement IoT-based irrigation system using LoRaWAN sensors for soil moisture, weather data integration, and ML-based water requirement prediction. Include variable rate irrigation (VRI) support, fertigation scheduling, and integration with John Deere Operations Center API.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["LoRaWAN gateway", "Weather API subscription", "ML model deployment"],
  "acceptance_criteria": [
    "Sensor data processed within 30 seconds",
    "ML predictions achieve 85% accuracy vs actual",
    "VRI maps generated for 100+ acre fields",
    "Water usage reduced by minimum 20%",
    "Offline mode supports 7 days operation"
  ],
  "technical_details": {
    "endpoints": ["/api/irrigation/schedule", "/api/sensors/moisture", "/api/vri/generate"],
    "models": ["SoilMoisture", "IrrigationZone", "CropWaterRequirement", "FertigationSchedule"],
    "services": ["LoRaWANGateway", "WeatherAPI", "TensorFlowServing", "JohnDeereAPI"],
    "standards": ["ISO 11783 (ISOBUS)", "AgGateway ADAPT", "GeoJSON", "WaterML 2.0"],
    "protocols": ["LoRaWAN", "MQTT", "CoAP", "Modbus RTU"]
  }
}

[IF domain == "automotive"]:
AUTOMOTIVE TASK EXAMPLE:
{
  "title": "Implement CAN bus diagnostics with OBD-II and UDS protocol support",
  "description": "Create vehicle diagnostics service supporting OBD-II PIDs and UDS (ISO 14229) for advanced diagnostics. Implement DTC (Diagnostic Trouble Code) management, ECU flashing capability, and real-time parameter monitoring. Add J2534 pass-through support for third-party tools.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["CAN interface hardware", "ECU documentation", "J2534 DLL"],
  "acceptance_criteria": [
    "CAN messages processed at 1ms intervals",
    "Support all Mode 01-0A OBD-II services",
    "ECU flash completes within 5 minutes",
    "DTC clearing follows SAE J2012 standard",
    "Supports 500kbps and 1Mbps CAN rates"
  ],
  "technical_details": {
    "endpoints": ["/api/diagnostics/scan", "/api/dtc/clear", "/api/ecu/flash"],
    "models": ["DiagnosticTroubleCode", "ECUInfo", "CANFrame", "FlashSequence"],
    "services": ["CANInterface", "UDSProtocol", "J2534PassThru", "DTCDatabase"],
    "standards": ["ISO 14229 (UDS)", "ISO 15765", "SAE J1979", "SAE J2534"],
    "protocols": ["CAN 2.0B", "ISO-TP", "KWP2000", "J1939"]
  }
}

[IF domain == "construction"]:
CONSTRUCTION TASK EXAMPLE:
{
  "title": "Build BIM integration with 4D scheduling and clash detection",
  "description": "Implement Building Information Modeling (BIM) integration using IFC format. Add 4D scheduling visualization linking 3D models to project timeline. Include automated clash detection between MEP systems. Support BCF (BIM Collaboration Format) for issue tracking.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["IFC parser library", "3D rendering engine", "Project schedule access"],
  "acceptance_criteria": [
    "IFC models up to 500MB load in <30 seconds",
    "Clash detection identifies 95% of conflicts",
    "4D simulation runs at 30+ FPS",
    "BCF 2.1 XML format fully supported",
    "Supports Level 3 BIM maturity"
  ],
  "technical_details": {
    "endpoints": ["/api/bim/upload", "/api/clash/detect", "/api/4d/simulate", "/api/bcf/issues"],
    "models": ["IFCModel", "ClashResult", "ScheduleActivity", "BCFIssue"],
    "services": ["IFCParser", "ClashDetector", "4DEngine", "BCFManager"],
    "standards": ["ISO 16739 (IFC)", "ISO 19650", "BCF 2.1", "COBie"],
    "formats": ["IFC4", "BCF-XML", "gbXML", "CityGML"]
  }
}

[IF domain == "consumer_goods"]:
CONSUMER GOODS TASK EXAMPLE:
{
  "title": "Implement GS1 compliant product serialization and traceability",
  "description": "Build product serialization system using GS1 standards for global traceability. Implement EPCIS event capture for supply chain visibility. Add GTIN allocation, serial number generation, and integration with GS1 Global Registry. Support both DataMatrix and RFID encoding.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["GS1 company prefix", "EPCIS repository", "Barcode/RFID hardware"],
  "acceptance_criteria": [
    "Generate 1M unique serials per hour",
    "EPCIS events captured within 500ms",
    "99.99% barcode read accuracy",
    "Support aggregation/disaggregation events",
    "Comply with EU FMD serialization rules"
  ],
  "technical_details": {
    "endpoints": ["/api/gtin/allocate", "/api/serial/generate", "/api/epcis/capture"],
    "models": ["ProductMaster", "SerialNumber", "EPCISEvent", "AggregationHierarchy"],
    "services": ["GS1Registry", "SerialGenerator", "EPCISRepository", "DataMatrixEncoder"],
    "standards": ["GS1 GTIN", "EPCIS 1.2", "GS1 Digital Link", "ISO/IEC 15459"],
    "encoding": ["DataMatrix", "GS1-128", "EPC Gen2 RFID", "QR Code"]
  }
}

[IF domain == "ecommerce" OR domain == "retail"]:
ECOMMERCE/RETAIL TASK EXAMPLE:
{
  "title": "Implement distributed inventory management with multi-channel sync",
  "description": "Build event-driven inventory service using Event Sourcing and CQRS. Sync inventory across stores, warehouses, and online channels. Implement optimistic locking, oversell protection, and automated reorder points. Include integration with POS systems and drop-ship vendors.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["Event store", "Message broker", "Cache layer", "POS API access"],
  "acceptance_criteria": [
    "Inventory updates propagate within 500ms",
    "Zero overselling during flash sales (10K req/sec)",
    "Automated reorders trigger at dynamic thresholds",
    "Support for kit/bundle inventory tracking",
    "Real-time ATP (Available to Promise) calculation"
  ],
  "technical_details": {
    "endpoints": ["/api/inventory/reserve", "/api/inventory/sync", "/api/inventory/atp"],
    "models": ["InventoryEvent", "StockLevel", "ReorderPoint", "ProductBundle"],
    "services": ["EventStore", "Apache Kafka", "Redis", "ElasticSearch"],
    "patterns": ["Event Sourcing", "CQRS", "Saga Pattern", "Optimistic Locking"],
    "integrations": ["Square POS", "Shopify", "ShipStation", "3PL APIs"]
  }
}

[IF domain == "education"]:
EDUCATION TASK EXAMPLE:
{
  "title": "Implement adaptive learning recommendation engine with xAPI tracking",
  "description": "Build ML-powered recommendation service using collaborative filtering and knowledge graphs. Track all learning interactions using xAPI statements to Learning Record Store (LRS). Implement Bloom's taxonomy level detection and prerequisite checking. Include SCORM package import/export for legacy content.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["ML model server", "Neo4j knowledge graph", "LRS instance"],
  "acceptance_criteria": [
    "Recommendations personalized based on learning style",
    "xAPI statements sent within 500ms of interaction",
    "Prerequisite gaps identified before content recommendation",
    "SCORM 2004 packages imported with 95% metadata retention",
    "Support for IMS QTI assessment format"
  ],
  "technical_details": {
    "endpoints": ["/api/recommendations", "/api/xapi/statements", "/api/content/scorm"],
    "models": ["LearnerProfile", "KnowledgeNode", "LearningPath", "xAPIStatement"],
    "services": ["TensorFlowServing", "Neo4j", "LearningRecordStore", "SCORMEngine"],
    "standards": ["xAPI 1.0.3", "SCORM 2004", "IMS QTI 2.2", "Caliper Analytics"],
    "algorithms": ["Collaborative Filtering", "Knowledge Tracing", "Item Response Theory"]
  }
}

[IF domain == "energy"]:
ENERGY TASK EXAMPLE:
{
  "title": "Build smart grid demand response system with IEC 61850 integration",
  "description": "Implement demand response platform supporting OpenADR 2.0b for automated load curtailment. Integrate with IEC 61850 compliant IEDs for real-time grid monitoring. Add predictive load forecasting using weather data and historical patterns. Include blockchain-based renewable energy credit tracking.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["IEC 61850 gateway", "OpenADR VTN", "Time-series database"],
  "acceptance_criteria": [
    "Grid telemetry processed within 100ms",
    "DR events dispatched to 10K endpoints in <30s",
    "Load forecast accuracy within 5% MAPE",
    "REC transactions immutably recorded",
    "Support for IEEE 2030.5 (SEP2) devices"
  ],
  "technical_details": {
    "endpoints": ["/api/dr/events", "/api/grid/telemetry", "/api/load/forecast", "/api/rec/mint"],
    "models": ["DREvent", "GridMeasurement", "LoadForecast", "RenewableCredit"],
    "services": ["IEC61850Client", "OpenADRVTN", "InfluxDB", "HyperledgerFabric"],
    "standards": ["OpenADR 2.0b", "IEC 61850", "IEEE 2030.5", "IEC 61968 (CIM)"],
    "protocols": ["GOOSE", "MMS", "DNP3", "Modbus TCP"]
  }
}

[IF domain == "entertainment_media"]:
ENTERTAINMENT/MEDIA TASK EXAMPLE:
{
  "title": "Implement adaptive bitrate streaming with DRM and CDN integration",
  "description": "Build video streaming service with HLS/DASH adaptive bitrate support. Implement multi-DRM (Widevine, FairPlay, PlayReady) with license server integration. Add CDN switching logic based on QoE metrics. Include server-side ad insertion (SSAI) with VAST/VMAP support.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["DRM license servers", "CDN contracts", "Transcoding pipeline"],
  "acceptance_criteria": [
    "Stream starts within 2 seconds",
    "Bitrate adaptation within 500ms of bandwidth change",
    "DRM license issued in <200ms",
    "SSAI ads inserted frame-accurately",
    "Support 4K HDR (HDR10/Dolby Vision)"
  ],
  "technical_details": {
    "endpoints": ["/api/manifest/hls", "/api/drm/license", "/api/cdn/select", "/api/ads/insert"],
    "models": ["VideoAsset", "DRMLicense", "QoEMetric", "AdBreak"],
    "services": ["TranscodingPipeline", "DRMGateway", "CDNOptimizer", "SSAIEngine"],
    "standards": ["HLS", "MPEG-DASH", "CMAF", "SCTE-35"],
    "formats": ["H.264/AVC", "H.265/HEVC", "AV1", "AAC", "E-AC3"]
  }
}

[IF domain == "environmental_services"]:
ENVIRONMENTAL SERVICES TASK EXAMPLE:
{
  "title": "Build IoT-based waste management with route optimization",
  "description": "Implement smart waste bin monitoring using ultrasonic sensors and NB-IoT connectivity. Create dynamic route optimization for collection vehicles using real-time fill levels. Add contamination detection using computer vision. Include carbon footprint tracking and reporting.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["NB-IoT network", "Route optimization API", "ML vision model"],
  "acceptance_criteria": [
    "Bin fill levels updated every 6 hours",
    "Routes optimize for <20% travel reduction",
    "Contamination detected with 90% accuracy",
    "Carbon savings calculated per ISO 14064",
    "Support 10K bins per deployment"
  ],
  "technical_details": {
    "endpoints": ["/api/bins/status", "/api/routes/optimize", "/api/contamination/detect"],
    "models": ["WasteBin", "CollectionRoute", "ContaminationEvent", "CarbonFootprint"],
    "services": ["NBIoTGateway", "OSRMRouter", "ComputerVision", "CarbonCalculator"],
    "standards": ["ISO 14064", "GHG Protocol", "WEEE Directive", "Basel Convention"],
    "protocols": ["NB-IoT", "LoRaWAN", "MQTT-SN", "CoAP"]
  }
}

[IF domain == "fintech" OR domain == "finance"]:
FINTECH/FINANCE TASK EXAMPLE:
{
  "title": "Implement PCI-compliant payment tokenization service",
  "description": "Create secure payment tokenization service using Stripe API. Implement /api/payments/tokenize endpoint with AES-256 encryption for card data in transit. Include PCI DSS compliance logging, fraud detection webhook integration, and automatic retry mechanism for failed transactions. Add rate limiting (100 req/min per user) and idempotency keys.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["Stripe API credentials", "SSL certificate configuration", "Audit logging service"],
  "acceptance_criteria": [
    "Card data never stored in application database",
    "All payment events logged to immutable audit trail",
    "Tokenization completes within 2 seconds",
    "Supports 3D Secure authentication flow",
    "Implements idempotency for duplicate requests"
  ],
  "technical_details": {
    "endpoints": ["/api/payments/tokenize", "/api/payments/3ds-callback", "/api/payments/webhook"],
    "models": ["PaymentToken", "TransactionAudit", "FraudScore", "IdempotencyKey"],
    "services": ["Stripe", "AuditLogger", "FraudDetectionService", "RateLimiter"],
    "compliance": ["PCI DSS Level 1", "GDPR Article 32", "SOX 404"],
    "security": ["TLS 1.3", "AES-256-GCM", "HMAC-SHA256 webhooks"]
  }
}

[IF domain == "food_beverage"]:
FOOD & BEVERAGE TASK EXAMPLE:
{
  "title": "Implement HACCP monitoring with blockchain traceability",
  "description": "Build HACCP (Hazard Analysis Critical Control Points) digital monitoring system with IoT temperature sensors. Implement blockchain-based supply chain traceability from farm to table. Add automated alerts for CCP deviations and predictive analytics for shelf life.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["IoT gateway", "Blockchain network", "Temperature sensors"],
  "acceptance_criteria": [
    "Temperature logged every 5 minutes",
    "CCP violations alert within 30 seconds",
    "Full supply chain trace in <10 seconds",
    "Shelf life predictions 95% accurate",
    "FDA FSMA compliance documented"
  ],
  "technical_details": {
    "endpoints": ["/api/haccp/monitor", "/api/trace/product", "/api/shelf-life/predict"],
    "models": ["CCPReading", "SupplyChainEvent", "ShelfLifeModel", "HACCPPlan"],
    "services": ["IoTHub", "HyperledgerFabric", "PredictiveAnalytics", "AlertEngine"],
    "compliance": ["FDA FSMA", "HACCP", "ISO 22000", "SQF"],
    "standards": ["GS1 EPCIS", "GFSI", "Codex Alimentarius"]
  }
}

[IF domain == "government_public_sector"]:
GOVERNMENT/PUBLIC SECTOR TASK EXAMPLE:
{
  "title": "Build citizen portal with digital identity verification",
  "description": "Implement secure citizen services portal with multi-factor authentication and digital identity verification. Support document upload with automated validation, case management workflow, and integration with legacy government systems. Include accessibility compliance (WCAG 2.1 AA).",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["Identity provider", "Document validator", "Legacy system APIs"],
  "acceptance_criteria": [
    "Identity verification completes in <30 seconds",
    "WCAG 2.1 AA compliance verified",
    "Support 50K concurrent citizens",
    "Document validation accuracy >95%",
    "Zero PII exposed in logs"
  ],
  "technical_details": {
    "endpoints": ["/api/citizen/verify", "/api/document/submit", "/api/case/status"],
    "models": ["CitizenProfile", "DigitalIdentity", "CaseWorkflow", "DocumentRecord"],
    "services": ["IdentityVerifier", "DocumentAI", "WorkflowEngine", "LegacyAdapter"],
    "compliance": ["NIST 800-63-3", "WCAG 2.1 AA", "FedRAMP", "Privacy Act"],
    "standards": ["OAuth 2.0", "SAML 2.0", "X.509", "PDF/A"]
  }
}

[IF domain == "healthcare"]:
HEALTHCARE TASK EXAMPLE:
{
  "title": "Build FHIR-compliant patient data access API with consent management",
  "description": "Implement RESTful API for patient records following FHIR R4 standard. Add granular consent management allowing patients to control data sharing at field level. Implement break-glass access for emergencies with supervisor approval workflow. Include C-CDA document generation for interoperability.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["HAPI FHIR server", "Consent management database", "Identity provider integration"],
  "acceptance_criteria": [
    "All PHI access logged with purpose of use codes",
    "Consent checks complete within 100ms",
    "Break-glass access triggers immediate alerts",
    "C-CDA documents validate against HL7 schemas",
    "Support for proxy access (guardians/caregivers)"
  ],
  "technical_details": {
    "endpoints": ["/fhir/Patient", "/fhir/Consent", "/fhir/AuditEvent", "/api/break-glass"],
    "models": ["Patient", "Consent", "AuditEvent", "ProxyAuthorization"],
    "services": ["FHIRValidator", "ConsentEngine", "CDSHooksService", "HL7Transformer"],
    "compliance": ["HIPAA 164.312", "21st Century Cures Act", "TEFCA"],
    "standards": ["FHIR R4", "C-CDA 2.1", "SMART on FHIR", "OAuth 2.0"]
  }
}

[IF domain == "hospitality_tourism"]:
HOSPITALITY/TOURISM TASK EXAMPLE:
{
  "title": "Implement dynamic pricing engine with channel management",
  "description": "Build ML-based revenue management system analyzing demand patterns, competitor rates, and local events. Integrate with channel managers (SiteMinder, Cloudbeds) for rate distribution. Add yield optimization and minimum length of stay (MLOS) rules. Support group bookings and packages.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["ML infrastructure", "Channel manager APIs", "PMS integration"],
  "acceptance_criteria": [
    "Rates updated across 10+ channels in <5 min",
    "RevPAR improvement of minimum 8%",
    "Support 100K pricing calculations/hour",
    "Package combinations computed in <2s",
    "Historical data analysis for 2+ years"
  ],
  "technical_details": {
    "endpoints": ["/api/pricing/calculate", "/api/channels/distribute", "/api/yield/optimize"],
    "models": ["PricingStrategy", "ChannelRate", "YieldRule", "PackageBundle"],
    "services": ["MLPricingEngine", "ChannelManager", "PMSConnector", "EventAnalyzer"],
    "standards": ["OTA XML", "HTNG", "HAPI", "STR benchmarking"],
    "integrations": ["SiteMinder", "Booking.com", "Expedia", "Opera PMS"]
  }
}

[IF domain == "insurance"]:
INSURANCE TASK EXAMPLE:
{
  "title": "Build AI-powered claims processing with fraud detection",
  "description": "Implement automated claims intake using OCR and NLP for document extraction. Add fraud detection ML model analyzing claim patterns, provider networks, and historical data. Include straight-through processing for low-risk claims and integration with core policy system.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["OCR service", "Fraud detection model", "Policy system API"],
  "acceptance_criteria": [
    "Document extraction accuracy >95%",
    "Fraud detection false positive rate <5%",
    "STP rate >60% for eligible claims",
    "Claims decision within 24 hours",
    "ACORD standard compliance"
  ],
  "technical_details": {
    "endpoints": ["/api/claims/submit", "/api/fraud/analyze", "/api/claims/adjudicate"],
    "models": ["Claim", "FraudScore", "PolicyCoverage", "ProviderNetwork"],
    "services": ["DocumentAI", "FraudDetector", "RulesEngine", "PolicyAdapter"],
    "standards": ["ACORD", "ICD-10", "CPT codes", "EDI 837"],
    "compliance": ["HIPAA", "State DOI regulations", "NAIC model laws"]
  }
}

[IF domain == "logistics" OR domain == "transportation"]:
LOGISTICS/TRANSPORTATION TASK EXAMPLE:
{
  "title": "Build real-time fleet tracking with geofencing and ELD compliance",
  "description": "Implement GPS tracking service with geofencing for 10,000+ vehicles. Integrate with ELD (Electronic Logging Device) for FMCSA compliance. Add predictive maintenance alerts based on vehicle diagnostics (OBD-II). Include route deviation detection and automated compliance reporting.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["GPS provider API", "PostGIS database", "ELD vendor SDK"],
  "acceptance_criteria": [
    "Location updates processed within 2 seconds",
    "Geofence entry/exit detected within 30 seconds",
    "HOS (Hours of Service) violations flagged immediately",
    "Predictive maintenance accuracy > 85%",
    "Support for offline data sync when connectivity restored"
  ],
  "technical_details": {
    "endpoints": ["/api/fleet/track", "/api/geofence", "/api/eld/logs", "/api/maintenance/predict"],
    "models": ["Vehicle", "Geofence", "DriverLog", "MaintenanceEvent"],
    "services": ["PostGIS", "TimescaleDB", "Apache Kafka", "TensorFlow"],
    "compliance": ["FMCSA ELD", "DOT regulations", "IFTA reporting"],
    "protocols": ["J1939", "OBD-II", "GTFS-Realtime", "ISO 15765"]
  }
}

[IF domain == "manufacturing"]:
MANUFACTURING TASK EXAMPLE:
{
  "title": "Build MES integration for real-time production monitoring",
  "description": "Implement OPC UA client for machine data collection from PLCs. Create real-time dashboard with OEE (Overall Equipment Effectiveness) calculation. Add predictive quality control using sensor data and ML. Include ISA-95 compliant data model and shift-based reporting.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["OPC UA server", "Time-series database", "ML pipeline"],
  "acceptance_criteria": [
    "Machine data collected at 100Hz frequency",
    "OEE calculated and displayed within 5 seconds",
    "Quality predictions achieve 90% accuracy",
    "Support for 50+ simultaneous PLC connections",
    "Automated alerts for parameter deviations"
  ],
  "technical_details": {
    "endpoints": ["/api/opc/subscribe", "/api/oee/calculate", "/api/quality/predict"],
    "models": ["ProductionOrder", "MachineState", "QualityMetric", "ShiftReport"],
    "services": ["OPC UA Client", "InfluxDB", "Apache Flink", "TensorFlow"],
    "standards": ["ISA-95", "OPC UA", "PackML", "ANSI/ISA-88"],
    "protocols": ["Modbus TCP", "EtherNet/IP", "PROFINET", "MQTT"]
  }
}

[IF domain == "mining_natural_resources"]:
MINING/NATURAL RESOURCES TASK EXAMPLE:
{
  "title": "Implement mine safety monitoring with predictive analytics",
  "description": "Build real-time monitoring for underground mine safety including gas sensors (CH4, CO, O2), ground stability sensors, and personnel tracking. Implement ML-based prediction for rockburst and equipment failure. Add emergency evacuation system with refuge chamber monitoring.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["SCADA system", "Sensor network", "ML infrastructure"],
  "acceptance_criteria": [
    "Gas readings updated every 10 seconds",
    "Rockburst prediction 30 minutes ahead",
    "Personnel location accurate to 5 meters",
    "Emergency alerts within 5 seconds",
    "99.99% system availability"
  ],
  "technical_details": {
    "endpoints": ["/api/safety/monitor", "/api/predict/rockburst", "/api/personnel/track"],
    "models": ["GasReading", "GroundStability", "PersonnelLocation", "EmergencyEvent"],
    "services": ["SCADAInterface", "MLPredictor", "RTLSEngine", "AlertDispatcher"],
    "standards": ["MSHA regulations", "IEC 61508", "ISA-100.11a", "WITS"],
    "protocols": ["Modbus", "DNP3", "IEC 61850", "WirelessHART"]
  }
}

[IF domain == "nonprofit_social_impact"]:
NONPROFIT/SOCIAL IMPACT TASK EXAMPLE:
{
  "title": "Build impact measurement platform with donor transparency",
  "description": "Implement outcome tracking system using Theory of Change methodology. Create donor portal showing real-time impact metrics and fund allocation. Add beneficiary feedback collection via SMS/WhatsApp. Include automated impact reporting aligned with SDG indicators.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 5,
  "complexity": "Medium",
  "dependencies": ["SMS gateway", "WhatsApp Business API", "GIS services"],
  "acceptance_criteria": [
    "Impact metrics updated within 24 hours",
    "Donor portal loads in <3 seconds",
    "SMS delivery rate >95%",
    "SDG alignment automatically calculated",
    "Support multilingual feedback (10+ languages)"
  ],
  "technical_details": {
    "endpoints": ["/api/impact/track", "/api/donor/dashboard", "/api/feedback/collect"],
    "models": ["ImpactMetric", "DonorContribution", "BeneficiaryFeedback", "SDGAlignment"],
    "services": ["TwilioSMS", "WhatsAppBusiness", "ImpactCalculator", "ReportGenerator"],
    "standards": ["SDG indicators", "IATI", "GRI Standards", "Theory of Change"],
    "integrations": ["Salesforce Nonprofit Cloud", "Twilio", "MapBox", "Google Translate"]
  }
}

[IF domain == "oil_gas"]:
OIL & GAS TASK EXAMPLE:
{
  "title": "Implement drilling optimization with real-time WITSML data",
  "description": "Build drilling parameter optimization system consuming WITSML 2.0 real-time data. Implement stuck pipe prediction using ML on historical drilling data. Add automated geosteering recommendations based on LWD data. Include HSE incident tracking and reporting.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["WITSML server", "ML infrastructure", "Drilling database"],
  "acceptance_criteria": [
    "WITSML data processed within 1 second",
    "Stuck pipe prediction 2 hours ahead",
    "Geosteering updates every 30 feet",
    "ROP optimization improves by 15%",
    "Zero data loss during transmission"
  ],
  "technical_details": {
    "endpoints": ["/api/witsml/stream", "/api/predict/stuckpipe", "/api/geosteering/recommend"],
    "models": ["DrillingParameter", "WellboreTrajectory", "FormationData", "HSEIncident"],
    "services": ["WITSMLClient", "MLPredictor", "GeosteeringEngine", "HSETracker"],
    "standards": ["WITSML 2.0", "PPDM", "API RP 754", "ISO 14224"],
    "protocols": ["WITSML", "OPC UA", "Modbus TCP", "MQTT"]
  }
}

[IF domain == "pharmaceuticals_biotech"]:
PHARMACEUTICALS/BIOTECH TASK EXAMPLE:
{
  "title": "Build clinical trial management with 21 CFR Part 11 compliance",
  "description": "Implement electronic data capture (EDC) system for clinical trials with full audit trail. Add randomization engine with stratification support. Include adverse event reporting with MedDRA coding. Ensure 21 CFR Part 11 compliance for electronic signatures.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["Randomization algorithm", "MedDRA dictionary", "E-signature service"],
  "acceptance_criteria": [
    "Complete audit trail for all data changes",
    "Randomization completed in <2 seconds",
    "AE reporting within regulatory timelines",
    "Electronic signatures cryptographically secure",
    "Support for adaptive trial designs"
  ],
  "technical_details": {
    "endpoints": ["/api/edc/capture", "/api/randomize/subject", "/api/ae/report"],
    "models": ["CRFData", "SubjectRandomization", "AdverseEvent", "AuditTrail"],
    "services": ["EDCEngine", "RandomizationService", "MedDRACoder", "ESignature"],
    "compliance": ["21 CFR Part 11", "ICH GCP", "GDPR", "CDISC standards"],
    "standards": ["CDISC ODM", "HL7 FHIR", "MedDRA", "WHO Drug"]
  }
}

[IF domain == "professional_services"]:
PROFESSIONAL SERVICES TASK EXAMPLE:
{
  "title": "Implement time tracking with automated billing and profitability analysis",
  "description": "Build intelligent time tracking system with project code prediction using ML. Integrate with billing system for automated invoice generation based on rate cards. Add real-time project profitability dashboard with resource utilization metrics. Include expense management with receipt OCR.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 5,
  "complexity": "Medium",
  "dependencies": ["Billing system API", "OCR service", "ML model"],
  "acceptance_criteria": [
    "Time entries auto-categorized with 90% accuracy",
    "Invoices generated within 24 hours of period close",
    "Profitability metrics updated hourly",
    "Receipt OCR extracts data with 95% accuracy",
    "Support for multiple currencies and tax rules"
  ],
  "technical_details": {
    "endpoints": ["/api/time/track", "/api/billing/generate", "/api/profitability/analyze"],
    "models": ["TimeEntry", "ProjectBilling", "ProfitabilityMetric", "ExpenseReport"],
    "services": ["MLCategorizer", "BillingEngine", "OCRService", "ReportGenerator"],
    "integrations": ["QuickBooks", "Salesforce", "Concur", "Office 365"],
    "standards": ["LEDES billing", "ISO 4217 (currency)", "GAAP", "SOC 2"]
  }
}

[IF domain == "real_estate"]:
REAL ESTATE TASK EXAMPLE:
{
  "title": "Build property valuation API with comparable analysis",
  "description": "Implement automated property valuation using ML on MLS data, tax records, and market trends. Add comparable property analysis with adjustments for features, location, and condition. Include integration with Zillow, Redfin APIs for market data. Support commercial and residential properties.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["MLS access", "Property data APIs", "ML infrastructure"],
  "acceptance_criteria": [
    "Valuations within 5% of appraised value",
    "Comparables selected from <0.5 mile radius",
    "API response time <3 seconds",
    "Support for 50+ property types",
    "Historical trend analysis for 10+ years"
  ],
  "technical_details": {
    "endpoints": ["/api/property/value", "/api/comps/analyze", "/api/market/trends"],
    "models": ["Property", "Comparable", "ValuationModel", "MarketTrend"],
    "services": ["MLValuationEngine", "MLSConnector", "GeocodingService", "TrendAnalyzer"],
    "integrations": ["MLS RETS/Web API", "Zillow", "CoreLogic", "Google Maps"],
    "standards": ["RESO Data Dictionary", "MISMO", "GeoJSON", "BOMA"]
  }
}

[IF domain == "security_safety"]:
SECURITY/SAFETY TASK EXAMPLE:
{
  "title": "Implement AI-powered threat detection with SIEM integration",
  "description": "Build behavioral anomaly detection system using unsupervised ML on network traffic, user behavior, and system logs. Integrate with SIEM platforms (Splunk, QRadar) via CEF/LEEF formats. Add automated incident response playbooks with SOAR integration. Include threat intelligence feed correlation.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["SIEM platform", "Threat intel feeds", "ML infrastructure"],
  "acceptance_criteria": [
    "Anomalies detected within 5 minutes",
    "False positive rate <10%",
    "SIEM events forwarded in <1 second",
    "Playbooks execute within 30 seconds",
    "Support 100K events/second ingestion"
  ],
  "technical_details": {
    "endpoints": ["/api/anomaly/detect", "/api/incident/respond", "/api/threat/correlate"],
    "models": ["SecurityEvent", "AnomalyScore", "IncidentPlaybook", "ThreatIndicator"],
    "services": ["MLAnomalyDetector", "SIEMConnector", "SOARIntegration", "ThreatIntel"],
    "standards": ["CEF", "LEEF", "STIX/TAXII", "MITRE ATT&CK"],
    "protocols": ["Syslog", "Kafka", "REST", "gRPC"]
  }
}

[IF domain == "sports_fitness"]:
SPORTS/FITNESS TASK EXAMPLE:
{
  "title": "Build athlete performance tracking with biometric integration",
  "description": "Implement real-time biometric data collection from wearables (heart rate, HRV, movement). Add ML-based performance prediction and injury risk assessment. Include training load management using TRIMP/ACWR methodologies. Support team-wide analytics and individual athlete dashboards.",
  "category": "backend",
  "time_estimate": 7,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["Wearable APIs", "ML models", "Video analysis system"],
  "acceptance_criteria": [
    "Biometric data synced within 30 seconds",
    "Injury risk predictions 80% accurate",
    "Support 100+ concurrent athletes",
    "Training load calculated in real-time",
    "Integration with 5+ wearable brands"
  ],
  "technical_details": {
    "endpoints": ["/api/biometrics/sync", "/api/performance/analyze", "/api/injury/predict"],
    "models": ["AthleteProfile", "BiometricReading", "TrainingLoad", "InjuryRisk"],
    "services": ["WearableSync", "MLPerformance", "VideoAnalyzer", "LoadCalculator"],
    "integrations": ["Garmin Connect", "Whoop", "Catapult", "Hudl"],
    "metrics": ["TRIMP", "ACWR", "HRV", "RPE", "GPS metrics"]
  }
}

[IF domain == "telecommunications"]:
TELECOMMUNICATIONS TASK EXAMPLE:
{
  "title": "Implement 5G network slicing orchestrator with SLA management",
  "description": "Build network slice lifecycle management using ETSI NFV MANO architecture. Implement dynamic resource allocation based on SLA requirements and network conditions. Add real-time KPI monitoring with automatic remediation. Support E2E slice orchestration across RAN, transport, and core.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["NFV orchestrator", "SDN controller", "5G core"],
  "acceptance_criteria": [
    "Slice provisioning within 5 minutes",
    "99.99% SLA compliance tracking",
    "Auto-scaling triggers within 30 seconds",
    "Support 1000+ concurrent slices",
    "E2E latency monitoring <1ms accuracy"
  ],
  "technical_details": {
    "endpoints": ["/api/slice/provision", "/api/sla/monitor", "/api/nfv/orchestrate"],
    "models": ["NetworkSlice", "SLATemplate", "VNF", "KPIMetric"],
    "services": ["NFVOrchestrator", "SDNController", "MonitoringEngine", "PolicyEngine"],
    "standards": ["3GPP Release 16", "ETSI NFV", "ONF SDN", "TMF APIs"],
    "protocols": ["NETCONF/YANG", "OpenFlow", "gRPC", "Kafka"]
  }
}

[IF domain == "workforce_management"]:
WORKFORCE MANAGEMENT TASK EXAMPLE:
{
  "title": "Build AI-powered workforce scheduling with compliance tracking",
  "description": "Implement intelligent scheduling engine considering skills, certifications, labor laws, and employee preferences. Add fatigue management for safety-critical roles. Include real-time attendance tracking with biometric integration. Support complex shift patterns and union rules.",
  "category": "backend",
  "time_estimate": 8,
  "story_points": 8,
  "complexity": "High",
  "dependencies": ["Biometric devices", "Payroll system", "ML infrastructure"],
  "acceptance_criteria": [
    "Schedules generated for 1000+ employees in <2 min",
    "100% labor law compliance validation",
    "Fatigue risk scores calculated hourly",
    "Shift swaps processed in real-time",
    "Integration with 3+ biometric systems"
  ],
  "technical_details": {
    "endpoints": ["/api/schedule/generate", "/api/attendance/track", "/api/compliance/validate"],
    "models": ["Schedule", "ShiftPattern", "ComplianceRule", "FatigueScore"],
    "services": ["SchedulingEngine", "BiometricInterface", "ComplianceChecker", "MLOptimizer"],
    "standards": ["ILO conventions", "FLSA", "Working Time Directive", "ISO 45001"],
    "integrations": ["ADP", "Kronos", "BioStar", "SAP SuccessFactors"]
  }
}

[DEFAULT - Technology/Software]:
TECHNOLOGY TASK EXAMPLE:
{
  "title": "Implement distributed tracing and observability pipeline",
  "description": "Set up OpenTelemetry instrumentation across all microservices. Configure Jaeger for distributed tracing with sampling strategies. Implement custom spans for business transactions. Add trace-metric correlation and automated anomaly detection.",
  "category": "backend",
  "time_estimate": 6,
  "story_points": 5,
  "complexity": "High",
  "dependencies": ["OpenTelemetry SDK", "Jaeger deployment", "Metrics backend"],
  "acceptance_criteria": [
    "All HTTP/gRPC calls automatically traced",
    "P95 latency for trace collection < 5ms",
    "Custom business metrics correlated with traces",
    "Anomaly detection triggers within 30 seconds",
    "Support for baggage propagation"
  ],
  "technical_details": {
    "endpoints": ["/api/traces", "/api/metrics", "/api/alerts"],
    "models": ["Trace", "Span", "Metric", "Alert"],
    "services": ["Jaeger", "Prometheus", "OpenTelemetry Collector"],
    "patterns": ["Context Propagation", "Sampling", "Tail-based Sampling"],
    "standards": ["OpenTelemetry", "W3C Trace Context", "OpenMetrics"]
  }
}

TASK GENERATION RULES:
1. Use domain-specific technical details from the examples above
2. Each task must include relevant compliance/standards for the domain
3. Reference actual tools, protocols, and services used in the domain
4. Include domain-specific performance requirements and SLAs
5. Consider regulatory and security requirements specific to the domain
6. Tasks should demonstrate deep domain knowledge
7. Use industry-standard terminology and acronyms appropriately

REQUIREMENTS (${max_tasks} tasks total):
1. Map each acceptance criterion to specific tasks
2. Maximum 8 hours per task (split larger tasks)
3. Include setup, implementation, and testing phases
4. Reference specific endpoints, models, and services
5. Tasks must be independently deployable
6. Consider error handling and monitoring
7. Use domain-specific technical details matching ${domain}
8. Include relevant compliance and standards
9. Reference appropriate design patterns and algorithms

Generate tasks following the structure of the domain-specific example that matches ${domain}.